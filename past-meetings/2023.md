# Monash NLP&ML Reading Group
---

- Time: Thursday, 1:00PM-2:30PM
- Location: Room 207 Woodside building
- Schedule: [here](https://docs.google.com/document/d/13qkZBy1KBCeFa5s72fMCaCXpthnTWSg0ft4Y9fJuxzw/edit?usp=sharing)
- Format: 
    - Main speaker -- Long presentation (~45 minutes) about research project, interesting paper, tutorial, in-depth discussion; 
    - Second speaker -- Short presentation on a topic of choice (30 minutes max). Some suggestions:
        - Overview of a list of related papers 
        - A tutorial of a research topic (NLP, ML/AI tasks, models, problems, etc.)
        - If the paper to be presented next week is fairly complicated, you can also provide the background of the problems/methods as preparation for next week.
    - Second speaker of the current week will be the main speaker of next week.
- [Past meeting repo](https://github.com/Monash-NLP-ML-Group/lab_reading_group)

## 2023 Schedule
### . EMNLP23 Redux
- Date: 2023 Dec 18

### 33. Block State Transformer
- Speaker: Jonathan Pilaut (Mila - Quebec Artificial Intelligence Institute)
- Date: 2023 Nov 23

### 32. Moral related natural language processing
- Main Speaker: Zhuang
- Date: 2023 Nov 16
- Second Speaker: Devin presents paper [Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models](https://arxiv.org/abs/2310.04406)

### 31. Human Alignment of LLMs
- Main Speaker: Trang
- Date: 2023 Nov 02
- [Slides](https://docs.google.com/presentation/d/1aQxsj_vZt97dfwcC8By6BfYwx7vj7GH3y843tpPB50A/edit?usp=sharing)
- Second Speaker: Zhuang presents the paper [Fact-Checking Complex Claims with Program-Guided Reasoning](https://aclanthology.org/2023.acl-long.386/)

### 30. [NExT-GPT: Any-to-Any Multimodal LLM](https://arxiv.org/abs/2309.05519)
- Main Speaker: Xiaoyu
- Date: 2023 October 26
- Second Speaker: Trang presents a short tutorial on [human alignment of LLMs](https://icml.cc/media/icml-2023/Slides/21554.pdf).

### 29. Think One More Step Beyond Knowledge Editing
- Main Speaker: Tong
- Date: 2023 October 19
- Related papers:
    - [Unveiling the Pitfalls of Knowledge Editing for Large Language Models](https://arxiv.org/abs/2310.02129)
    - [Evaluating the Ripple Effects of Knowledge Editing in Language Models](https://arxiv.org/abs/2307.12976)
- Second Speaker: Xiaoyu presents the paper [Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models](https://arxiv.org/abs/2308.16463)

### 28. Quantisation for compressing LLMs
- Main Speaker: Reza
- Date: 2023 October 05
- Second Speaker: Tong presents the paper [The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”](https://owainevans.github.io/reversal_curse.pdf)
### 27. Long Context Language Models
- Main Speaker: Tao
- Date: 2023 September 14
- Related papers: 
    - [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)
    - [L-Eval: Instituting Standardized Evaluation for Long Context Language Models](https://arxiv.org/abs/2307.11088)
    - [LongNet: Scaling Transformers to 1,000,000,000 Tokens](https://arxiv.org/abs/2307.02486)
- Second Speaker: Reza will talk about 'Recent Advances in Quantisation for Compressing LLMs', covering following papers:
    - [8-bit Optimizers via Block-wise Quantization](https://arxiv.org/abs/2110.02861)
    - [LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale](https://arxiv.org/abs/2208.07339)
    - [The case for 4-bit precision: k-bit Inference Scaling Laws](https://arxiv.org/abs/2212.09720)
    - [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
    - [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323)

### 26. Word Associations as a source of Commonsense Knowledge
- Main Speaker: Chunhua Liu (Melbourne Uni)
- Date: 2023 September 7
- Abstract: Commonsense knowledge is what helps us make sense of everyday situations and is important for AI systems to truly understand and interact with humans. However, acquiring this knowledge is challenging because it is implicit and diverse, leading to sparsity issues within existing commonsense resources. We explore a new approach: using large-scale word associations as a source of commonsense knowledge. Word associations are spontaneous connections that individuals make, such as associating "smile" with "happy", reflecting the human mental lexicon. We propose using large-scale word associations to complement existing knowledge resources and improve how natural language processing models reason with commonsense. In this talk, I will present three key research questions: (1) What relational knowledge is encoded in word associations? (2) Can large-scale word associations improve performance on downstream commonsense reasoning tasks? (3) Can word associations contribute to extracting implicit knowledge from pre-trained language models? By addressing these questions, we aim to deepen our understanding of word associations, highlight their practical utility, and offer a new way to extract commonsense knowledge from language models.
- BIO: Chunhua a PhD student in natural language processing at The University of Melbourne under the supervision of Trevor Cohn and Lea Frermann. Her research interests center around understanding the structure and relationships between concepts through interdisciplinary perspectives, including natural language processing and cognitive psychology. With a specific emphasis on understanding the structure and reasons behind human word associations, evaluating the potential of word associations as a source of commonsense knowledge and incorporating commonsense knowledge to improve neural models' reasoning ability on tasks, such as commonsense question answering and natural language inferences. Additionally, She is interested in exploring concept representation and categorization across languages and cultures.
- Second speaker: Linhao  will present the paper [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/abs/2308.09687)

### 25. Recent Advances in Object Detection in the Wild
- Main Speaker: Chuang
- Date: 2023 August 31

### 24. [KOSMOS-2: Grounding Multimodal Large Language Models to the World](https://arxiv.org/abs/2306.14824)
- Main Speaker: Chuang
- Date: 2023 August 24

### 23. [Editing Large Language Models: Problems, Methods, and Opportunities](https://arxiv.org/abs/2305.13172)
- Main Speaker: Linhao
- Date: 2023 August 17
- [Slides](https://drive.google.com/file/d/1aAAvG8NMHXmYTsskGitF7A2iv-xTrju3/view?usp=drive_link)
- Second speaker: Hao will have a practice talk for his Interspeech paper [Investigating Pre-trained Audio Encoders in the Low-Resource Condition](https://arxiv.org/abs/2305.17733)

### 22. [Cross-Modal Fine-Tuning: Align then Refine](https://arxiv.org/abs/2302.05738)
- Main Speaker: Haolan
- Date: 2023 August 10
- Second speaker: Fatemeh will discuss the paper [Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning](https://arxiv.org/abs/2304.02711)

### 21. Measuring Dataset Distance via Optimal Transport
- Haolan
- Date: 2023 August 03
- Paper: [Geometric Dataset Distances via Optimal Transport](https://arxiv.org/abs/2002.02923)

### 20. ACL Redux
- Reza shares his findings at ACL2023
- Date: 2023 July 27

### 19. ACL Redux
- Lizhen shares his findings at ACL2023
- Date: 2023 July 20
- Resources: [Slide](https://docs.google.com/presentation/d/1scIkI_aUwYQeoWy7Nt3JpYeQeQH9Yda3u_CxFt1FXh8/edit?usp=sharing)

### 18. Multi-modal instruction tuning
- Main Speaker: Xiaoyu
- Date: 2023 July 04
- Second speaker: Fatemeh with discuss following papers:
    - [Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models](https://arxiv.org/abs/2306.06891)
    - [Decomposed Prompting: A Modular Approach for Solving Complex Tasks](https://arxiv.org/abs/2210.02406)
    - [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)

### 17. Large Language Model’s Theory of Mind
- Main Speaker: Farhad
- Date: 2023 June 29
- Related papers:
    - [Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks](https://arxiv.org/abs/2302.08399)
    - [Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker](https://arxiv.org/abs/2306.00924)
- Second speaker: Xiaoyu will discuss following papers:
    - [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485)
    - [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2302.00923)
    
### 16. [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models](https://arxiv.org/abs/2301.12503)
- Main Speaker: Manh
- Date: 2023 June 22
- Second Speaker: Farhad will discuss papers about Large Language Model’s Theory of Mind, covering following paper:
    - [Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models](https://arxiv.org/abs/2305.14763)


### 15. Can multiple large language models (LLMs) improve each other via self-playing?
- Main Speaker: Devin
- Date: 2023 June 15
- Related papers:
    - [Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback](https://arxiv.org/abs/2305.10142)
    - [Improving Factuality and Reasoning in Language Models through Multiagent Debate](https://arxiv.org/abs/2305.14325)
- Second Speaker: Manh will discuss the paper [AudioGen: Textually Guided Audio Generation](https://arxiv.org/abs/2209.15352)

### 14. [Complementary Explanations for Effective In-Context Learning](https://arxiv.org/abs/2211.13892)
- Main Speaker: Zhuang
- Date: 2023 June 1
- Devin presents talk with title "Language Models can teach themselves to perform better", discussing the following papers:
    - [Language Models Can Teach Themselves to Program Better](https://arxiv.org/abs/2207.14502)
    - [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244)
    - [Progressive-Hint Prompting Improves Reasoning in Large Language Models](https://arxiv.org/abs/2304.09797)

### 13. Large Language Models
- Main Speaker: Reza
- Date: 2023 May 25
- Related papers:
    - [Improving Code Generation by Training with Natural Language Feedback](https://arxiv.org/abs/2303.16749)
    - [PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs](https://arxiv.org/abs/2305.12392)
    - [Training Language Models with Language Feedback at Scale](https://arxiv.org/abs/2303.16755)
    - [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback](https://tatsu-lab.github.io/alpaca_farm_paper.pdf)

### 12. Meta skills for doing research
- Main Speaker: Prof. Waleed Abdulla from the University of Auckland
- Date: 2023 May 18

### 11. Tutorial on Continual Learning in NLP
- Main Speaker: Tong
- Date: 2023 May 04
- Trang will discuss a few papers on refining large language models
    - [Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback](https://arxiv.org/abs/2302.12813)
    - [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)
    - [REFINER: Reasoning Feedback on Intermediate Representations](https://arxiv.org/abs/2304.01904)
    
### 10. Planning with Large Language Models
- Main Speaker: Reza
- Related papers:
    - [Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language](https://arxiv.org/abs/2204.00598)
    - [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://arxiv.org/abs/2204.01691)
    - [Inner Monologue: Embodied Reasoning through Planning with Language Models](https://arxiv.org/abs/2207.05608)
    - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)
- Date: 2023 Apr 27
- Tong will give a tutorial on continual learning.

### 9. Multimodal Language Model
- Main Speaker: Chuang
- Date: 2023 Mar 30
- Related papers:
    - [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)
    - [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671)
- Reza will discuss a series of papers on large language models.
    - [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity](https://arxiv.org/abs/2302.04023)
    - [PDDL PLANNING WITH PRETRAINED LARGE LANGUAGE MODELS](https://openreview.net/forum?id=1QMMUB4zfl)
    - [SELF-INSTRUCT: Aligning Language Model with Self Generated Instructions](https://arxiv.org/abs/2212.10560)
    - [AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS](https://arxiv.org/abs/2210.03493)
    - [LARGE LANGUAGE MODELS ARE NOT ZERO-SHOT COMMUNICATORS](https://arxiv.org/abs/2210.14986)
    - [Hello Dolly: Democratizing the magic of ChatGPT with open models](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)
    - [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)

### 8. Tutorials on Instruction Tuning
- Main Speaker: Minghao
- Date: 2023 Mar 23
- Related papers:
    - [Finetuned Language Models are Zero-Shot Learners](https://arxiv.org/abs/2109.01652)
    - [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416)
    - [Self-Instruct: Aligning Language Model with Self Generated Instructions](https://arxiv.org/abs/2212.10560)
- Chuang will present the paper [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)

### 7. Dataset creation for Simultaneous Machine Translation (cont)
- Main Speaker: Michelle
- Date: 2023 Mar 16
- Minghao will present the paper [Language Modelling with Pixels](https://openreview.net/forum?id=FkSp8VW8RjH)

### 6. Dataset creation for Simultaneous Machine Translation
- Date: 2023 Mar 09
- Michelle will share her internship experience.

### 5. [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/abs/2106.13884)
- Main Speaker: Farhad
- Date: 2023 Mar 02

### 4. [DSM: Question Generation over Knowledge Base via Modeling Diverse Subgraphs with Meta-learner](https://aclanthology.org/2022.emnlp-main.281/)
- Main Speaker: Linhao
- Date: 2023 Feb 23
- Short presentation by Farhad about multimodal few-shot learning

### 3. [Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners](https://arxiv.org/abs/2205.10747)
- Main Speaker: Haolan
- Date: 2023 Feb 16
- Short presentation by Linhao about generating questions based on knowledge graphs


### 2. [Learning Disentangled Semantic Representations for Zero-Shot Cross-Lingual Transfer in Multilingual Machine Reading Comprehension](https://aclanthology.org/2022.acl-long.70/)
- Main Speaker: Devin
- Date: 2023 Feb 09
- Short presentation by Haolan with the title "Dialog Inpainting: Turning Documents into Dialogs"

### 1. Self-training strategy in computer vision
- Main Speaker: Samitha
- Date: 2023 Feb 02
- Related papers:
    - [Adversarial Masking for Self-Supervised Learning](https://arxiv.org/abs/2201.13100)
    - [Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency](https://arxiv.org/abs/2206.08222)
    - [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf)

