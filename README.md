# Monash NLP&ML Reading Group
---

- Time: Thursday, 1:00PM-2:30PM
- Location: Room 207 Woodside building
- Schedule: [here](https://docs.google.com/document/d/13qkZBy1KBCeFa5s72fMCaCXpthnTWSg0ft4Y9fJuxzw/edit?usp=sharing)
- Format: 
    - Main speaker -- Long presentation (~45 minutes) about research project, interesting paper, tutorial, in-depth discussion; 
    - Second speaker -- Short presentation on a topic of choice (30 minutes max). Some suggestions:
        - Overview of a list of related papers 
        - A tutorial of a research topic (NLP, ML/AI tasks, models, problems, etc.)
        - If the paper to be presented next week is fairly complicated, you can also provide the background of the problems/methods as preparation for next week.
    - Second speaker of the current week will be the main speaker of next week.
- [Past meeting repo](https://github.com/Monash-NLP-ML-Group/lab_reading_group)

## 2023 Schedule
### 16. [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models](https://arxiv.org/abs/2301.12503)
- Main Speaker: Manh
- Date: 2023 June 22
- Second Speaker: Farhad will discuss papers about Large Language Modelâ€™s Theory of Mind

### 15. Can multiple large language models (LLMs) improve each other via self-playing?
- Main Speaker: Devin
- Date: 2023 June 15
- Related papers:
    - [Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback](https://arxiv.org/abs/2305.10142)
    - [Improving Factuality and Reasoning in Language Models through Multiagent Debate](https://arxiv.org/abs/2305.14325)
- Second Speaker: Manh will discuss the paper [AudioGen: Textually Guided Audio Generation](https://arxiv.org/abs/2209.15352)

### 14. [Complementary Explanations for Effective In-Context Learning](https://arxiv.org/abs/2211.13892)
- Main Speaker: Zhuang
- Date: 2023 June 1
- Devin presents talk with title "Language Models can teach themselves to perform better", discussing the following papers:
    - [Language Models Can Teach Themselves to Program Better](https://arxiv.org/abs/2207.14502)
    - [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244)
    - [Progressive-Hint Prompting Improves Reasoning in Large Language Models](https://arxiv.org/abs/2304.09797)

### 13. Large Language Models
- Main Speaker: Reza
- Date: 2023 May 25
- Related papers:
    - [Improving Code Generation by Training with Natural Language Feedback](https://arxiv.org/abs/2303.16749)
    - [PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs](https://arxiv.org/abs/2305.12392)
    - [Training Language Models with Language Feedback at Scale](https://arxiv.org/abs/2303.16755)
    - [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback](https://tatsu-lab.github.io/alpaca_farm_paper.pdf)

### 12. Meta skills for doing research
- Main Speaker: Prof. Waleed Abdulla from the University of Auckland
- Date: 2023 May 18

### 11. Tutorial on Continual Learning in NLP
- Main Speaker: Tong
- Date: 2023 May 04
- Trang will discuss a few papers on refining large language models
    - [Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback](https://arxiv.org/abs/2302.12813)
    - [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)
    - [REFINER: Reasoning Feedback on Intermediate Representations](https://arxiv.org/abs/2304.01904)
    
### 10. Planning with Large Language Models
- Main Speaker: Reza
- Related papers:
    - [Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language](https://arxiv.org/abs/2204.00598)
    - [Do As I Can, Not As I Say: Grounding Language in Robotic Affordances](https://arxiv.org/abs/2204.01691)
    - [Inner Monologue: Embodied Reasoning through Planning with Language Models](https://arxiv.org/abs/2207.05608)
    - [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)
- Date: 2023 Apr 27
- Tong will give a tutorial on continual learning.

### 9. Multimodal Language Model
- Main Speaker: Chuang
- Date: 2023 Mar 30
- Related papers:
    - [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)
    - [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671)
- Reza will discuss a series of papers on large language models.
    - [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity](https://arxiv.org/abs/2302.04023)
    - [PDDL PLANNING WITH PRETRAINED LARGE LANGUAGE MODELS](https://openreview.net/forum?id=1QMMUB4zfl)
    - [SELF-INSTRUCT: Aligning Language Model with Self Generated Instructions](https://arxiv.org/abs/2212.10560)
    - [AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS](https://arxiv.org/abs/2210.03493)
    - [LARGE LANGUAGE MODELS ARE NOT ZERO-SHOT COMMUNICATORS](https://arxiv.org/abs/2210.14986)
    - [Hello Dolly: Democratizing the magic of ChatGPT with open models](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html)
    - [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)

### 8. Tutorials on Instruction Tuning
- Main Speaker: Minghao
- Date: 2023 Mar 23
- Related papers:
    - [Finetuned Language Models are Zero-Shot Learners](https://arxiv.org/abs/2109.01652)
    - [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416)
    - [Self-Instruct: Aligning Language Model with Self Generated Instructions](https://arxiv.org/abs/2212.10560)
- Chuang will present the paper [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)

### 7. Dataset creation for Simultaneous Machine Translation (cont)
- Main Speaker: Michelle
- Date: 2023 Mar 16
- Minghao will present the paper [Language Modelling with Pixels](https://openreview.net/forum?id=FkSp8VW8RjH)

### 6. Dataset creation for Simultaneous Machine Translation
- Date: 2023 Mar 09
- Michelle will share her internship experience.

### 5. [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/abs/2106.13884)
- Main Speaker: Farhad
- Date: 2023 Mar 02

### 4. [DSM: Question Generation over Knowledge Base via Modeling Diverse Subgraphs with Meta-learner](https://aclanthology.org/2022.emnlp-main.281/)
- Main Speaker: Linhao
- Date: 2023 Feb 23
- Short presentation by Farhad about multimodal few-shot learning

### 3. [Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners](https://arxiv.org/abs/2205.10747)
- Main Speaker: Haolan
- Date: 2023 Feb 16
- Short presentation by Linhao about generating questions based on knowledge graphs


### 2. [Learning Disentangled Semantic Representations for Zero-Shot Cross-Lingual Transfer in Multilingual Machine Reading Comprehension](https://aclanthology.org/2022.acl-long.70/)
- Main Speaker: Devin
- Date: 2023 Feb 09
- Short presentation by Haolan with the title "Dialog Inpainting: Turning Documents into Dialogs"

### 1. Self-training strategy in computer vision
- Main Speaker: Samitha
- Date: 2023 Feb 02
- Related papers:
    - [Adversarial Masking for Self-Supervised Learning](https://arxiv.org/abs/2201.13100)
    - [Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency](https://arxiv.org/abs/2206.08222)
    - [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf)

