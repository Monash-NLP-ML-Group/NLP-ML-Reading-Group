# Monash NLP&ML Reading Group
---

- Time: Thursday, 1:00PM-2:30PM
- Location: Room 280 Woodside building
- Schedule: [here](https://docs.google.com/document/d/13qkZBy1KBCeFa5s72fMCaCXpthnTWSg0ft4Y9fJuxzw/edit?usp=sharing)
- Format: [Presentation guidelines](presenter-guideline.md)
    - First speaker (~45 minutes) -- The presenter talks about her/his current work/projects (the goal is to increase awareness about your work and get feedback from the team).
    - Second speaker (~45 minutes) -- The presentation about a set of papers, or a tutorial about a topic of the presenter's choice.
- [Past meeting repo](past-meetings)

## 2024 Schedule
### 7. Audio Safety on Multimodal LLMs
- Date: 2024 Feb 29
- First Speaker: Hao presents his work about "Audio Safety on Multimodal LLMs".
- Second speaker: Tao will discuss the following papers
    - [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality](https://arxiv.org/abs/2305.00050)
    - [Causal Parrots: Large Language Models May Talk Causality But Are Not Causal](https://openreview.net/forum?id=tv46tCzs83)

### 6. Towards Socially-aware Dialogue Systems
- Date: 2024 Feb 22
- First speaker: Haolan presents his work about "Towards Socially-aware Dialogue Systems".
- Second speaker: Hao will discuss the following papers
    - [GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse](https://arxiv.org/abs/2401.01523)
    - [Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models](https://arxiv.org/abs/2401.13298)

### 5. Research at MonashNLP
- Date: 2024 Feb 08
- First speaker: Reza will present an overview on different directions and projects that our groups are currently working on.
- Second speaker: Haolan will discuss the following papers
    - [Aligning Large Language Models through Synthetic Feedback](https://aclanthology.org/2023.emnlp-main.844)
    - [Tool-Augmented Reward Modeling](https://arxiv.org/abs/2310.01045)

### 4. Bridging the Modality Gap between Speech and Text
- Date: 2024 Feb 01
- First speaker: Michelle presents her work about "Bridging the Modality Gap between Speech and Text".
- Second speaker: Fatemeh will present few works about multi-modal LLMs, including
    - [Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs](https://arxiv.org/abs/2401.06209)
    - [How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs](https://arxiv.org/abs/2311.16101)
### 3. Modelling Coalition Negotiations Using Artificial Agents
- Date: 2024 Jan 25
- First speaker: Farhad will present his work on "Modelling Coalition Negotiations Using Artificial Agents"
- Second speaker: Michelle will share her internship experience at FAIR

### 2. Simultaneous Machine Translation with Large Language Models
- Date: 2024 Jan 18
- First speaker: Minghan presents his work about "Simultaneous Machine Translation with Large Language Models".
- Second speaker: Farhad will present few works about "Multi-agent Conversation", including
    - [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155)
    - [MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework](https://arxiv.org/abs/2308.00352)

### 1. [Don't throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding](https://arxiv.org/abs/2309.15028)
- Date: 2024 Jan 11
- First speaker: Devin presents paper [Don't throw away your value model! Making PPO even better via Value-Guided Monte-Carlo Tree Search decoding](https://arxiv.org/abs/2309.15028)
- Second speaker: Minghan presents paper [Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models](https://arxiv.org/abs/2311.07919)
